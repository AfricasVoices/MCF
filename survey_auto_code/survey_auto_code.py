import argparse
import os
import time
from os import path
import hashlib
from dateutil.parser import isoparse
import jsonpickle
import datetime
import json

from core_data_modules.cleaners import swahili, Codes
from core_data_modules.traced_data import Metadata, TracedData
from core_data_modules.traced_data.io import TracedDataJsonIO, TracedDataCodaIO
from core_data_modules.util import IOUtils, PhoneNumberUuidTable


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Cleans the wt surveys and exports variables to Coda for "
                                                 "manual verification and coding")
    parser.add_argument("user", help="User launching this program, for use by TracedData Metadata")
    parser.add_argument("json_input_path", metavar="json-input-path",
                        help="Path to input file, containing a list of serialized TracedData objects as JSON")
    parser.add_argument("prev_coded_path", metavar="prev-coded-path",
                        help="Directory containing Coda files generated by a previous run of this pipeline stage. "
                             "New data will be appended to this file.")
    parser.add_argument("phone_uuid_table_path", metavar="phone-uuid-table-path",
                        help="JSON file containing an existing phone number <-> UUID lookup table.")
    parser.add_argument("json_output_path", metavar="json-output-path",
                        help="Path to a JSON file to write processed TracedData messages to")
    parser.add_argument("coded_output_path", metavar="coding-output-path",
                        help="Directory to write coding files to")
    parser.add_argument("age_scheme_path")

    args = parser.parse_args()
    user = args.user
    json_input_path = args.json_input_path
    prev_coded_path = args.prev_coded_path
    phone_uuid_table_path = args.phone_uuid_table_path
    json_output_path = args.json_output_path
    coded_output_path = args.coded_output_path
    age_scheme_path = args.age_scheme_path

     # TODO: Move to CoreModules
    CODE_IDS = {"Scheme-12cb6f95": {"female": "code-86a4602c", "male": "code-63dcde9a", "NA": "code-NA-3498451d", "NS": "code-NS-5334289d",
     "NC": "code-NC-11d6bb91", "NR": "code-NR-03dd5d73"}, "Scheme-38460800af16": {}}

    CONTROL_CODES = ["NA", "NC", "WS"]

    with open(age_scheme_path, "r") as f:
        age_scheme = json.load(f)

    age_codes = age_scheme["Codes"]
    for code in age_codes:
            if "ControlCode" in code:
                code_text = code["ControlCode"]
            else:
                code_text = code["DisplayText"]
            CODE_IDS["Scheme-38460800af16"][code_text] = code["CodeID"]            

    class CleaningPlan:
        def __init__(self, raw_field, clean_field, coda_name, cleaner, scheme_id):
            self.raw_field = raw_field
            self.clean_field = clean_field
            self.coda_name = coda_name
            self.cleaner = cleaner
            self.scheme_id = scheme_id

    cleaning_plan = [
        CleaningPlan("Gender (Text) - mcf_demog", "gender_clean", "Gender",
                     swahili.DemographicCleaner.clean_gender, "Scheme-12cb6f95"),
        CleaningPlan("Location (Text) - mcf_demog", "location_clean", "Location",
                     None, "Scheme-59ad3a2d3086"),
        CleaningPlan("Education (Text) - mcf_demog", "education_clean", "Education",
                     None, "Scheme-a57ce8d15245"),
        CleaningPlan("Age (Text) - mcf_demog", "age_clean", "Age",
                     swahili.DemographicCleaner.clean_age,
                    "Scheme-38460800af16"),
        CleaningPlan("Work (Text) - mcf_demog", "work_clean", "Work", None,
                     "Scheme-12be1d8f34eb"),
        CleaningPlan("Training (Text) - mcf_demog", "training_clean", "Training",
                     None, "Scheme-8f0794281bb1"),
    ]

    # Load phone number UUID table
    with open(phone_uuid_table_path, "r") as f:
        phone_uuids = PhoneNumberUuidTable.load(f)

    # Load data from JSON file
    with open(json_input_path, "r") as f:
        data = TracedDataJsonIO.import_json_to_traced_data_iterable(f)

    # Filter out test messages sent by AVF
    contacts = [td for td in data if not td.get("test_run", False)]

    # Mark missing entries in the raw data as true missing
    for td in data:
        missing = dict()
        for plan in cleaning_plan:
            if plan.raw_field not in td:
                missing[plan.raw_field] = Codes.TRUE_MISSING
        td.append_data(missing, Metadata(user, Metadata.get_call_location(), time.time()))

    # Exclude missing data
    for plan in cleaning_plan:
        data = [td for td in data if td[plan.raw_field] not in {Codes.TRUE_MISSING, Codes.SKIPPED, Codes.NOT_LOGICAL}]

    # Clean all responses, add MessageID and Labels
    for td in data:
        cleaned = dict()
        message_id = dict()
        labels = dict()
        for plan in cleaning_plan:
            hash_object = hashlib.sha256()
            hash_object.update(td[plan.raw_field].encode('utf-8'))
            message_id_string = hash_object.hexdigest()
            message_id_key = "{} MessageID".format(plan.raw_field)
            message_id[message_id_key] = message_id_string
            labels_key = "{} Labels".format(plan.raw_field)
            labels[labels_key] = []
            if plan.cleaner is not None:
                label = dict()
                cleaned[plan.clean_field] = str(plan.cleaner(td[plan.raw_field]))
                code_id = CODE_IDS[plan.scheme_id][cleaned[plan.clean_field]]
                origin = {"OriginType":"Automatic","OriginID": "https://github.com/AfricasVoices/Project-MCF/pull/7", "Name": "survey_auto_code", "Metadata": {}}
                label["Checked"] = False
                label["Confidence"] = 0
                label["SchemeID"] = plan.scheme_id
                label["CodeID"] = code_id
                label["DateTimeUTC"] = datetime.datetime.utcnow().isoformat()
                label["Origin"] = origin
                labels[labels_key].append(label)
        td.append_data(cleaned, Metadata(user, Metadata.get_call_location(), time.time()))
        td.append_data(message_id, Metadata(user, Metadata.get_call_location(), time.time()))
        td.append_data(labels, Metadata(user, Metadata.get_call_location(), time.time()))

    # Write json output
    IOUtils.ensure_dirs_exist_for_file(json_output_path)
    with open(json_output_path, "w") as f:
        TracedDataJsonIO.export_traced_data_iterable_to_json(data, f, pretty_print=True)
    
    # Output for manual verification + coding
    IOUtils.ensure_dirs_exist(coded_output_path)
    for plan in cleaning_plan:
        coded_output_file_path = path.join(coded_output_path, "{}.json".format(plan.coda_name))
        message_ids = list()
        messages_to_code = list()
        for td in data:
                output = dict()        
                output["Labels"] = td["{} Labels".format(plan.raw_field)]
                output["MessageID"] = td["{} MessageID".format(plan.raw_field)]
                output["Text"] = str(td[plan.raw_field])
                output["CreationDateTimeUTC"] = isoparse(td["{} (Time) - {}".format(plan.coda_name, "mcf_demog")]).isoformat()
                if output["MessageID"] not in message_ids:
                    messages_to_code.append(output)
                    message_ids.append(output["MessageID"])
        with open(coded_output_file_path, "w") as f:
            jsonpickle.set_encoder_options("json", sort_keys=True)
            f.write(jsonpickle.dumps(messages_to_code))
            f.write("\n")
            